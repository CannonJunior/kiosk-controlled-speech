Metadata-Version: 2.4
Name: kiosk-controlled-speech
Version: 0.1.0
Summary: Voice-controlled kiosk system using MCP framework
Author-email: Kiosk Team <team@example.com>
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: mcp>=0.1.0
Requires-Dist: asyncio-mqtt
Requires-Dist: pydantic>=2.0.0
Requires-Dist: python-dotenv
Requires-Dist: loguru
Requires-Dist: typer
Requires-Dist: rich
Requires-Dist: faster-whisper>=0.10.0
Requires-Dist: sounddevice
Requires-Dist: numpy
Requires-Dist: opencv-python
Requires-Dist: pillow
Requires-Dist: pyautogui
Requires-Dist: pywin32; sys_platform == "win32"
Requires-Dist: pynput
Requires-Dist: aiofiles
Requires-Dist: httpx
Requires-Dist: websockets
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Requires-Dist: pytest-asyncio; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: isort; extra == "dev"
Requires-Dist: flake8; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Requires-Dist: pre-commit; extra == "dev"

# Kiosk Controlled Speech System

A voice-controlled interface system for Pandasuite kiosks using the FastMCP framework. This system enables natural language voice commands to control kiosk interactions on Windows through WSL with discrete service lifespans.

## Architecture Overview

The system uses **FastMCP** with discrete service lifespans instead of continuously running services:

- **Speech-to-Text Service**: Real-time voice recognition using FastMCP
- **Screen Capture Service**: Windows desktop capture from WSL
- **Mouse Control Service**: Windows mouse automation from WSL  
- **Screen Detector Service**: Computer vision-based screen state detection
- **Ollama Agent Service**: Natural language command processing
- **Data Manager Service**: Kiosk configuration and element management
- **Main Orchestrator**: Coordinates all services using FastMCP Client pattern

### New Architecture Benefits

- **Discrete Lifespans**: Services start/stop on-demand rather than running continuously
- **Better Resource Management**: No persistent connections to maintain
- **Simplified Deployment**: Uses FastMCP's battle-tested patterns
- **Improved Error Handling**: FastMCP manages connection lifecycle automatically

## Features

- üé§ **Real-time Speech Recognition**: Continuous voice command processing
- üñ•Ô∏è **Cross-platform Screen Capture**: Windows desktop capture from WSL environment
- üñ±Ô∏è **Intelligent Mouse Control**: Precise click automation with validation
- ü§ñ **AI-powered Command Processing**: Natural language understanding via Ollama
- üéØ **Computer Vision Detection**: Automatic screen state and element recognition
- üìä **Performance Monitoring**: Real-time metrics and health monitoring
- üîß **Hot-swappable Configuration**: Dynamic kiosk data management

## Quick Start

### Prerequisites

- Windows 10/11 with WSL2 enabled
- Python 3.9+ in WSL environment
- Ollama installed and running
- Audio device access from WSL

### Installation

1. **Clone and setup the project:**
```bash
git clone <repository-url>
cd kiosk-project
```

2. **Install dependencies using uv:**
```bash
# Install uv if not already installed
curl -LsSf https://astral.sh/uv/install.sh | sh

# Initialize project and install dependencies
uv sync
```

3. **Dependencies are managed automatically:**
```bash
# With uv, dependencies are automatically managed
# No need to manually activate environments - use 'uv run' prefix
```

4. **Service dependencies are managed via pyproject.toml:**
```bash
# All dependencies including service-specific ones are in pyproject.toml
# Run any additional service setup if needed
```

### Configuration

1. **Kiosk Data Configuration** (`config/kiosk_data.json`):
   - Define screens, elements, and voice commands
   - Set detection criteria for screen identification
   - Configure global commands and settings

2. **MCP Services Configuration** (`config/mcp_config.json`):
   - Configure MCP server endpoints
   - Set service-specific parameters
   - Define orchestration settings

### Running the System

1. **Quick test of all FastMCP services:**
```bash
# Run comprehensive service test using uv
uv run python test_fastmcp_services.py
```

2. **Test individual FastMCP services:**
```bash
# Test mouse control service
timeout 5 uv run python services/mouse_control/mcp_server.py

# Test screen detector service
timeout 5 uv run python services/screen_detector/mcp_server.py

# Test speech-to-text service
timeout 5 uv run python services/speech_to_text/mcp_server_fastmcp.py
```

3. **Start the full system:**
```bash
uv run python -m src.orchestrator.main start
```

4. **Test individual commands:**
```bash
uv run python -m src.orchestrator.main test-command "click start button"
```

### Testing FastMCP Services

Each service can be tested independently using FastMCP's built-in capabilities:

```bash
# Test mouse control tools
uv run python -c "
import asyncio
from fastmcp import Client

async def test_mouse():
    config = {'mcpServers': {'mouse_control': {'command': 'python', 'args': ['services/mouse_control/mcp_server.py']}}}
    async with Client(config) as client:
        result = await client.call_tool('mouse_control_click', {'x': 100, 'y': 200})
        print('Mouse click result:', result)

asyncio.run(test_mouse())
"

# Test screen detector tools
uv run python -c "
import asyncio
from fastmcp import Client

async def test_detector():
    config = {'mcpServers': {'screen_detector': {'command': 'python', 'args': ['services/screen_detector/mcp_server.py']}}}
    async with Client(config) as client:
        tools = await client.list_tools()
        print('Available tools:', [t.name for t in tools])

asyncio.run(test_detector())
"
```

## Usage

### Voice Commands

The system supports natural language commands:

- **Navigation**: "click start", "go back", "open menu"
- **Help**: "help", "what can I do", "show commands"  
- **Global**: "go home", "return to main screen"

### System Status

The orchestrator provides real-time status including:
- Voice recognition status
- Current screen detection
- Command processing metrics
- Service health monitoring

## Development

### Project Structure

```
kiosk-controlled-speech/
‚îú‚îÄ‚îÄ src/                          # Core application code
‚îÇ   ‚îú‚îÄ‚îÄ mcp/                     # MCP framework base classes
‚îÇ   ‚îú‚îÄ‚îÄ data_manager/            # Kiosk data management
‚îÇ   ‚îî‚îÄ‚îÄ orchestrator/            # Main orchestration logic
‚îú‚îÄ‚îÄ services/                    # MCP microservices
‚îÇ   ‚îú‚îÄ‚îÄ speech_to_text/         # Whisper-based speech recognition
‚îÇ   ‚îú‚îÄ‚îÄ screen_capture/         # Windows screenshot capture
‚îÇ   ‚îú‚îÄ‚îÄ mouse_control/          # Mouse automation
‚îÇ   ‚îú‚îÄ‚îÄ screen_detector/        # Computer vision detection
‚îÇ   ‚îî‚îÄ‚îÄ ollama_agent/           # AI command processing
‚îú‚îÄ‚îÄ config/                      # Configuration files
‚îú‚îÄ‚îÄ scripts/                     # Setup and utility scripts
‚îî‚îÄ‚îÄ tests/                       # Test suite
```

### Adding New Screens

1. **Update kiosk data** (`config/kiosk_data.json`):
```json
{
  "screens": {
    "new_screen": {
      "name": "New Screen",
      "description": "Description of the screen",
      "detection_criteria": {
        "title_text": "Screen Title",
        "elements": ["button1", "button2"]
      },
      "elements": [
        {
          "id": "button1",
          "name": "Button Name",
          "coordinates": {"x": 100, "y": 200},
          "size": {"width": 150, "height": 50},
          "voice_commands": ["click button", "press button"],
          "conditions": ["always_visible"],
          "action": "click",
          "next_screen": "target_screen"
        }
      ]
    }
  }
}
```

2. **Test screen detection**:
```bash
uv run python -m src.orchestrator.main test-command "navigate to new screen"
```

### Adding Voice Commands

1. **Element-specific commands**: Add to element's `voice_commands` array
2. **Global commands**: Add to `global_commands` section
3. **Context-aware commands**: Handled automatically by Ollama agent

### FastMCP Tool Naming Convention

FastMCP tools use their function names directly:

- Mouse control service tools: `click`, `move_to`, `get_position`, `drag`, `scroll`, `configure`
- Screen detector tools: `detect_current_screen`, `analyze_screen_elements`
- Speech service tools: `start_listening`, `stop_listening`, `get_status`, `process_audio_data`
- Screen capture tools: `take_screenshot`, `get_screen_info`

When multiple services are used together, tool names must be unique across all services to avoid conflicts.

### Performance Tuning

- **Speech Recognition**: Adjust `WHISPER_MODEL` and `SPEECH_LANGUAGE` in `.env`
- **Screen Detection**: Tune confidence thresholds in kiosk data
- **Response Time**: Configure `MAX_RESPONSE_TIME_MS` and Ollama parameters

## FastMCP Services

The system now uses FastMCP with discrete service lifespans. Each service exposes tools that are called on-demand.

### Speech-to-Text Service

**FastMCP Tools:**
- `start_listening`: Begin continuous speech recognition
- `stop_listening`: Stop speech recognition  
- `process_audio_data`: Process audio data
- `get_status`: Get current recognition status

**Testing:**
```bash
# Test speech service
uv run python -c "
import asyncio
from fastmcp import Client

async def test_speech():
    config = {'mcpServers': {'speech_to_text': {'command': 'python', 'args': ['services/speech_to_text/mcp_server_fastmcp.py']}}}
    async with Client(config) as client:
        result = await client.call_tool('start_listening')
        print('Speech recognition started:', result.content[0].text)

asyncio.run(test_speech())
"
```

### Screen Capture Service

**FastMCP Tools:**
- `take_screenshot`: Full desktop capture
- `get_screen_info`: Get screen dimensions and info

**Testing:**
```bash
# Test screen capture
uv run python -c "
import asyncio
from fastmcp import Client

async def test_capture():
    config = {'mcpServers': {'screen_capture': {'command': 'python', 'args': ['services/screen_capture/mcp_server.py']}}}
    async with Client(config) as client:
        result = await client.call_tool('take_screenshot')
        print('Screenshot taken:', result.content[0].text)

asyncio.run(test_capture())
"
```

### Mouse Control Service

**FastMCP Tools:**
- `click`: Perform mouse click at coordinates
- `move_to`: Move cursor to position
- `drag`: Drag between positions
- `scroll`: Scroll at position
- `get_position`: Get current cursor position
- `configure`: Configure mouse settings

**Testing:**
```bash
# Test mouse control (returns mock data for safety)
uv run python -c "
import asyncio
import json
from fastmcp import Client

async def test_mouse():
    config = {'mcpServers': {'mouse_control': {'command': 'python', 'args': ['services/mouse_control/mcp_server.py']}}}
    async with Client(config) as client:
        # List available tools
        tools = await client.list_tools()
        print('Mouse tools:', [t.name for t in tools])
        
        # Test click (mock implementation)
        result = await client.call_tool('click', {'x': 100, 'y': 200})
        print('Click result:', json.loads(result.content[0].text))

asyncio.run(test_mouse())
"
```

### Screen Detector Service

**FastMCP Tools:**
- `detect_current_screen`: Identify current screen
- `analyze_screen_elements`: Find clickable elements

**Testing:**
```bash
# Test screen detection
uv run python -c "
import asyncio
import json
from fastmcp import Client

async def test_detector():
    config = {'mcpServers': {'screen_detector': {'command': 'python', 'args': ['services/screen_detector/mcp_server.py']}}}
    async with Client(config) as client:
        # Test screen detection with mock data
        result = await client.call_tool('detect_current_screen', {
            'screenshot_data': 'mock_base64_data',
            'screen_definitions': {'home': {'name': 'Home Screen'}}
        })
        data = json.loads(result.content[0].text)
        print('Detected screen:', data['detected_screen'])

asyncio.run(test_detector())
"
```

### Ollama Agent Service

**FastMCP Tools:**
- `process_voice_command`: Convert speech to actions
- `generate_help_response`: Contextual help
- `analyze_intent`: Intent classification
- `health_check`: Check Ollama connectivity

**Prerequisites:**
```bash
# Install and start Ollama
curl -fsSL https://ollama.ai/install.sh | sh
ollama serve &
ollama pull qwen2.5:1.5b  # Or your preferred model
```

**Testing:**
```bash
# Test Ollama agent (requires Ollama running)
uv run python -c "
import asyncio
from fastmcp import Client

async def test_ollama():
    config = {'mcpServers': {'ollama_agent': {'command': 'python', 'args': ['services/ollama_agent/mcp_server.py']}}}
    async with Client(config) as client:
        # Check Ollama health
        health = await client.call_tool('health_check')
        print('Ollama health:', health.content[0].text)

asyncio.run(test_ollama())
"
```

## Troubleshooting

### Common Issues

1. **Audio not working in WSL**:
   - Ensure PulseAudio is configured: `export PULSE_RUNTIME_PATH="/mnt/wslg/runtime/PulseAudio"`
   - Test with: `uv run python -c "import sounddevice; print(sounddevice.query_devices())"`

2. **Screenshot capture fails**:
   - Verify WSL can access Windows desktop: `powershell.exe Get-Process`
   - Check Windows interop is enabled

3. **Ollama connection errors**:
   - Ensure Ollama is running: `ollama serve`
   - Check model is available: `ollama list`
   - Verify network configuration

4. **Mouse clicks not working**:
   - Run as administrator if needed
   - Check coordinate validation settings
   - Verify Windows permissions

### Debug Mode

Enable verbose logging:
```bash
export LOG_LEVEL=DEBUG
uv run python -m src.orchestrator.main start
```

### Health Checks

Monitor FastMCP service health:
```bash
# Test all services individually using uv

# Quick service tests
timeout 3 uv run python services/mouse_control/mcp_server.py || echo "Mouse service OK"
timeout 3 uv run python services/screen_detector/mcp_server.py || echo "Screen detector OK"
timeout 3 uv run python services/screen_capture/mcp_server.py || echo "Screen capture OK"
timeout 3 uv run python services/speech_to_text/mcp_server_fastmcp.py || echo "Speech service OK"

# Test full system integration
uv run python -c "
import asyncio
import json
from fastmcp import Client

async def health_check():
    config = {
        'mcpServers': {
            'mouse_control': {'command': 'python', 'args': ['services/mouse_control/mcp_server.py']},
            'screen_detector': {'command': 'python', 'args': ['services/screen_detector/mcp_server.py']},
            'screen_capture': {'command': 'python', 'args': ['services/screen_capture/mcp_server.py']}
        }
    }
    
    async with Client(config) as client:
        # List tools from all servers
        tools = await client.list_tools()
        print(f'Total tools available: {len(tools)}')
        
        # Test a simple tool call
        result = await client.call_tool('get_position')
        data = json.loads(result.content[0].text)
        print('Mouse position test:', data)

asyncio.run(health_check())
"
```

### FastMCP Debugging

Enable FastMCP debugging:
```bash
# Run individual service with verbose output
FASTMCP_DEBUG=1 uv run python services/mouse_control/mcp_server.py

# Check tool definitions
uv run python -c "
import asyncio
from fastmcp import Client

async def debug_tools():
    config = {'mcpServers': {'mouse_control': {'command': 'python', 'args': ['services/mouse_control/mcp_server.py']}}}
    async with Client(config) as client:
        tools = await client.list_tools()
        for tool in tools:
            print(f'Tool: {tool.name} - {tool.description}')

asyncio.run(debug_tools())
"
```

## Performance Metrics

The system tracks:
- **Response Time**: End-to-end command processing time (target: <500ms)
- **Recognition Accuracy**: Voice command recognition rate (target: >95%)
- **Click Precision**: Mouse positioning accuracy (target: ¬±5 pixels)
- **Uptime**: System availability (target: >99.5%)

## Security Considerations

- **Sandboxed Execution**: MCP services run in isolated processes
- **Input Validation**: All coordinates and commands are validated
- **Access Control**: Limited to kiosk application interactions
- **Audit Logging**: All actions are logged for review

## Contributing

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/new-feature`
3. **Make changes and test**: `uv run python scripts/test_system.py`
4. **Submit a pull request**

### Development Guidelines

- Follow PEP 8 style guidelines
- Add type hints to all functions
- Include docstrings for public APIs
- Write tests for new functionality
- Update documentation

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Support

For questions and support:
- Check the troubleshooting section
- Review the test outputs
- Submit issues with system logs
- Include configuration details in bug reports
